{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from natsort import natsort_keygen\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import nilearn\n",
    "from nilearn.connectome import ConnectivityMeasure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "\n",
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "                                                    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "'''\n",
    "From the documentation:\n",
    "The list of labels does not contain ‘Background’ by default. \n",
    "To have proper indexing, you should either manually add ‘Background’ to the list of labels:\n",
    "'''\n",
    "\n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")\n",
    "\n",
    "masker = NiftiLabelsMasker(\n",
    "    labels_img=schaefer_atlas.maps,\n",
    "    strategy='mean',  # Averages voxels in parcel at each TR\n",
    "    standardize=False  # don't want z-scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='purple'>IS-RSA</font>\n",
    "\n",
    "We take our parcellated timeseries for each of our clips, with each subject per row, and create a correlation matrix. We take the lower triangle of this correlated matrix and then correlate it with the lower triangle of the behavioral rating data correlation matrix.  \n",
    "\n",
    "We will do this for each movie separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important! Insert the correct variables before running:\n",
    "\n",
    "type = \"_\"+\"IM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_clip_path = '/Volumes/LT/phd/inarr/'\n",
    "sublist = [x for x in os.listdir(segmented_clip_path) if 'sub' in x]\n",
    "complete_cliplist = []\n",
    "\n",
    "#compile all of the clip files across subjects\n",
    "for sub in sublist:\n",
    "    try:\n",
    "        segment_list = [x for x in os.listdir(segmented_clip_path+sub+os.sep+\"segmented_files/\") if type in x]\n",
    "\n",
    "        for f in segment_list:\n",
    "            complete_cliplist.append(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "movie_list = ['physical', 'stutterer']\n",
    "\n",
    "im_clips = ['clip-1','clip-3','clip-5','clip-7','clip-9','clip-11','clip-13',\n",
    "             'clip-15','clip-17','clip-19','clip-21','clip-23']\n",
    "\n",
    "nim_clips = ['clip-0','clip-2','clip-4','clip-6','clip-8','clip-10','clip-12',\n",
    "             'clip-14','clip-16','clip-18','clip-20','clip-22','clip-24']\n",
    "\n",
    "df = pd.read_csv('behavioral_matrix.csv')\n",
    "phys_df = df[(df.target == 'physical')].copy()\n",
    "stut_df = df[(df.target == 'stutterer')].copy()\n",
    "\n",
    "phys_df.sort_values(by=['version', 'subID'], key=natsort_keygen(), inplace=True)\n",
    "stut_df.sort_values(by=['version', 'subID'], key=natsort_keygen(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_X = phys_df[['bossy','conscientious', 'easygoing', 'humble', 'nosy', 'rebellious']].values\n",
    "phys_distance_matrix = pairwise_distances(phys_X, metric='euclidean')\n",
    "\n",
    "stut_X = stut_df[['bossy','conscientious', 'easygoing', 'humble', 'nosy', 'rebellious']].values\n",
    "stut_distance_matrix = pairwise_distances(stut_X, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting clip: clip-1\n",
      "starting clip: clip-3\n",
      "starting clip: clip-5\n",
      "starting clip: clip-7\n",
      "starting clip: clip-9\n",
      "starting clip: clip-11\n",
      "starting clip: clip-13\n",
      "starting clip: clip-15\n",
      "starting clip: clip-17\n",
      "starting clip: clip-19\n",
      "starting clip: clip-21\n",
      "starting clip: clip-23\n"
     ]
    }
   ],
   "source": [
    "for movie in movie_list[0:1]:\n",
    "\n",
    "    if movie == 'physical':\n",
    "        distance_matrix =  phys_distance_matrix\n",
    "    elif movie == 'stutterer':\n",
    "         distance_matrix = stut_distance_matrix\n",
    "\n",
    "    movie_cliplist = [x for x in complete_cliplist if movie in x]\n",
    "    clip_to_behavior_correlation = np.zeros([12,400]) #IM is 12, NIM is 13\n",
    "\n",
    "    for ix, i in enumerate(im_clips):\n",
    "        print(\"starting clip:\", i)\n",
    "        filtered_clips = [x for x in movie_cliplist if i+\"_\" in x]\n",
    "        \n",
    "        v1_clips = [x for x in filtered_clips if 'version-1' in x]\n",
    "        v2_clips = [x for x in filtered_clips if 'version-2' in x]\n",
    "\n",
    "        single_clip_matrix_list = []\n",
    "\n",
    "        for clip in v1_clips:\n",
    "\n",
    "            fname = clip.split(\"_\")\n",
    "            sub, movie, clipnum = fname[0], fname[1], fname[2]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sub+'/segmented_files/'+clip)\n",
    "            \"\"\" \n",
    "            masker.fit_transform(clip_segment_nii) will take the voxelwise mean (ie it preserves\n",
    "            timecourse information). This produces a timepoint x parcel csv, eg for physical's \n",
    "            clip_0, it will generate a (74,40) shape.\n",
    "            \"\"\"\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) #producess a timepoint x parcel csv, eg (2, 400)\n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        for clip in v2_clips:\n",
    "\n",
    "            fname = clip.split(\"_\")\n",
    "            sub, movie, clipnum = fname[0], fname[1], fname[2]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sub+'/segmented_files/'+clip)\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) #producess a timepoint x parcel csv, eg (2, 400)\n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        single_clip_mat_arr = np.array(single_clip_matrix_list)\n",
    "\n",
    "        for p in range(400):\n",
    "\n",
    "            subject_by_timeseries = [] # eg., clip-0 has 28 subjects, and a timeseries of 78\n",
    "\n",
    "            for subject in range(single_clip_mat_arr.shape[0]): #go through each subject\n",
    "                subject_by_timeseries.append(single_clip_mat_arr[subject,:,p]) #grab the clip timeseries\n",
    "\n",
    "            clipdf = pd.DataFrame(subject_by_timeseries)\n",
    "            cliparr = np.corrcoef(clipdf)\n",
    "\n",
    "            neural_lower = nilearn.connectome.sym_matrix_to_vec(cliparr, discard_diagonal=True)\n",
    "            behavior_lower = nilearn.connectome.sym_matrix_to_vec(distance_matrix, discard_diagonal=True)\n",
    "\n",
    "            result = np.corrcoef(neural_lower, behavior_lower)[0][1]\n",
    "            clip_to_behavior_correlation[ix,p] = result\n",
    "    \n",
    "    output = pd.DataFrame(clip_to_behavior_correlation)\n",
    "    output.to_csv(movie+\"_clips_by_parcel_IM.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color ='turquoise'> Averaging the results & Plotting </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the IM and NIM dataframes, average them across clips and then average them across movies\n",
    "phys_im, stut_im = \n",
    "phys_nim, stut_nim = \n",
    "\n",
    "im_corr_vals = list(im_df['t_value'])\n",
    "nim_corr_vals = list(nim_df['t_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, datasets, image, surface\n",
    "import nibabel as nb\n",
    "from nilearn.plotting import plot_img_on_surf\n",
    "from nilearn.image import new_img_like\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "\n",
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "\n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = nb.load(schaefer_atlas.maps) # .maps provides the path to the map\n",
    "atlas_data = atlas.get_fdata()\n",
    "affine = atlas.affine\n",
    "\n",
    "mapped_data = np.zeros_like(atlas_data)\n",
    "mapped_data[atlas_data == 0] = np.nan # mark\n",
    "unique_regions = np.unique(atlas_data)[1:]\n",
    "\n",
    "for i, region in enumerate(unique_regions):\n",
    "    mapped_data[atlas_data == region] = t_vals[i] #NOT TVALS BUT NIM AND IM CORR  VALS\n",
    "\n",
    "#Create corrected p-value mask:\n",
    "n_rois = 399\n",
    "\n",
    "roi_data = image.get_data(atlas)  # (x,y,z) array with ROI labels\n",
    "significant_mask = np.zeros_like(roi_data, dtype=np.float32)\n",
    "\n",
    "for roi_label in range(1, n_rois+1):\n",
    "    if significant[roi_label-1] == 1:  # ROI labels start at 1\n",
    "        significant_mask[roi_data == roi_label] = 1  # Tag significant voxels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_corr_img = nb.Nifti1Image(mapped_data, affine)\n",
    "nb.save(im_corr_img, 'im_corr_map.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img_on_surf(im_corr_img,\n",
    "    \"fsaverage\", inflate=True,\n",
    "    views=['lateral', 'medial'],  # Hemispheric views to display\n",
    "    hemispheres=['left', 'right'],  # Both hemispheres\n",
    "    threshold=0.05,  # Highlight significant p-values\n",
    "    cmap='seismic',  # Colormap (e.g., 'viridis', 'coolwarm')\n",
    "    colorbar=True,  # Show colorbar\n",
    "    # vmin=0, vmax=.4, #removing these options to let it be automatic\n",
    ")\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If time allows, we will test our results with a permutation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
