{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from natsort import natsort_keygen\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import statsmodels.api as sm\n",
    "import nibabel as nb\n",
    "import nilearn\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='teal'>Preparing the rating data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgoldenrod'>Dartmouth participants rating data</font>\n",
    "Compute the absolute difference between each pair of rating participants (who rated the same trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('behavioral_matrix.csv')\n",
    "phys_df = df[(df.target == 'physical')].copy()\n",
    "stut_df = df[(df.target == 'stutterer')].copy()\n",
    "\n",
    "phys_df.sort_values(by=['version', 'subID'], key=natsort_keygen(), inplace=True)\n",
    "stut_df.sort_values(by=['version', 'subID'], key=natsort_keygen(), inplace=True)\n",
    "\n",
    "phys_X = phys_df[['bossy','conscientious', 'easygoing', 'humble', 'nosy', 'rebellious']].values\n",
    "phys_distance_matrix = pairwise_distances(phys_X, metric='euclidean')\n",
    "\n",
    "stut_X = stut_df[['bossy','conscientious', 'easygoing', 'humble', 'nosy', 'rebellious']].values\n",
    "stut_distance_matrix = pairwise_distances(stut_X, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgoldenrod'>CloudResearch participants rating data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the average distances among the participants who saw the same version of the same clip for a given movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(df, movie, trait, clip):\n",
    "    #distance among v1 group\n",
    "    v1_df = df[ (df.movie == movie) & (df.version == 1) & (df.trait == trait) & (df['round'] == clip) ].copy()\n",
    "    v1_ratings_arr = np.array(v1_df.ratings).reshape(-1,1)\n",
    "    v1_ratings_distances = pairwise_distances(v1_ratings_arr, metric='euclidean')\n",
    "    v1_lower_triangle = nilearn.connectome.sym_matrix_to_vec(v1_ratings_distances, discard_diagonal=True)\n",
    "    v1_rating_avg = v1_lower_triangle.mean()\n",
    "\n",
    "    #distance among v2 group\n",
    "    v2_df = df[ (df.movie == movie) & (df.version == 2) & (df.trait == trait) & (df['round'] == clip) ].copy()\n",
    "    v2_ratings_arr = np.array(v2_df.ratings).reshape(-1,1)\n",
    "    v2_ratings_distances = pairwise_distances(v2_ratings_arr, metric='euclidean')\n",
    "    v2_lower_triangle = nilearn.connectome.sym_matrix_to_vec(v2_ratings_distances, discard_diagonal=True)\n",
    "    v2_rating_avg = v2_lower_triangle.mean()\n",
    "\n",
    "    #compare across version groups: \n",
    "    v1_vs_v2 = pairwise_distances(v1_ratings_arr, v2_ratings_arr, metric='euclidean')\n",
    "    v1_vs_v2_avg = v1_vs_v2.mean()\n",
    "\n",
    "    return v1_rating_avg, v2_rating_avg, v1_vs_v2_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='teal'> IS-RSA</font>\n",
    "\n",
    "We take our parcellated timeseries for each of our clips, with each subject per row, and create a correlation matrix. We take the lower triangle of this correlated matrix and then correlate it with the lower triangle of the behavioral rating data correlation matrix.  \n",
    "\n",
    "We will do this for each movie separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTANT! Start by selecting the intended monologue type before running:\n",
    "\"\"\"\n",
    "monologue_type = \"IM\"\n",
    "#monologue_type = \"NIM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_clip_path = '/Volumes/Scraplab/fSEND/inarr_data/'\n",
    "sublist = [x for x in os.listdir(segmented_clip_path) if 'sub' in x]\n",
    "complete_cliplist = []\n",
    "\n",
    "type = \"_\"+monologue_type\n",
    "\n",
    "#compile all of the clip files across subjects\n",
    "for sub in sublist:\n",
    "    try:\n",
    "        segment_list = [x for x in os.listdir(segmented_clip_path+sub+os.sep+\"segmented_files/\") if type in x]\n",
    "\n",
    "        for f in segment_list:\n",
    "            complete_cliplist.append(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "movie_list = ['physical', 'stutterer']\n",
    "traitlist = ['Rebellious', 'Nosy', 'Easygoing', 'Humble', 'Bossy','Conscientious']\n",
    "\n",
    "im_clips = ['clip-1','clip-3','clip-5','clip-7','clip-9','clip-11','clip-13',\n",
    "             'clip-15','clip-17','clip-19','clip-21','clip-23']\n",
    "\n",
    "nim_clips = ['clip-2','clip-4','clip-6','clip-8','clip-10','clip-12',\n",
    "             'clip-14','clip-16','clip-18','clip-20','clip-22','clip-24'] #we drop the first clip, clip-0!\n",
    "\n",
    "if monologue_type == \"IM\":\n",
    "    working_list = im_clips\n",
    "elif monologue_type == \"NIM\":\n",
    "    working_list = nim_clips\n",
    "\n",
    "# ONLINE PARTICIPANTS DATA \n",
    "cloud_ratings = pd.read_csv(\"/Users/lindseytepfer/Documents/phd/inarr/online-results/inarr-online-unstacked.csv\")\n",
    "version_matrix = np.loadtxt(\"version_matrix_ISrsa.csv\",delimiter=\",\", dtype=str, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "                                                    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "\n",
    "masker = NiftiLabelsMasker(\n",
    "    labels_img=schaefer_atlas.maps,\n",
    "    strategy='mean',  # Averages voxels in parcel at each TR\n",
    "    standardize=False  # don't want z-scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movie_list[0:1]:\n",
    "\n",
    "    movie_cliplist = [x for x in complete_cliplist if movie in x]\n",
    "\n",
    "    clip_to_behavior_correlation = np.zeros([12,400])\n",
    "\n",
    "    for cx, clip in enumerate(working_list[1:2]):\n",
    "\n",
    "        clip_number = int(clip.split(\"-\")[1])\n",
    "        trait_arr = np.empty([6,3])\n",
    "\n",
    "        for ix, trait in enumerate(traitlist):\n",
    "            trait_arr[ix,:] = calculate_distances(cloud_ratings, movie, trait, clip_number)\n",
    "        \n",
    "        #get v1, v2, and v1v2 values:\n",
    "        trait_avg = trait_arr.mean(axis=0)\n",
    "\n",
    "        #build out clip-specific rating matrix based on participant version matrix\n",
    "        rating_matrix = np.empty([28,28])\n",
    "\n",
    "        for r in range(28):\n",
    "            for c in range(28):\n",
    "                if version_matrix[r,c] == 'v1v1':\n",
    "                    rating_matrix[r,c] = trait_avg[0]\n",
    "                elif version_matrix[r,c] == 'v2v2':\n",
    "                    rating_matrix[r,c] = trait_avg[1]\n",
    "                else:\n",
    "                    rating_matrix[r,c] = trait_avg[2]\n",
    "\n",
    "        #now resume building the clip's subject-wide ISC matrix\n",
    "        filtered_clips = [x for x in movie_cliplist if clip+\"_\" in x]\n",
    "        \n",
    "        #this ensures that the subject order matches the distance_matrices orders\n",
    "        v1_subs = natsorted([x for x in filtered_clips if 'version-1' in x])\n",
    "        v2_subs = natsorted([x for x in filtered_clips if 'version-2' in x])\n",
    "\n",
    "        single_clip_matrix_list = []\n",
    "\n",
    "        for sub in v1_subs:\n",
    "\n",
    "            sname = sub.split(\"_\")[0]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sname+'/segmented_files/'+sub)\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) #producess a timepoint x parcel csv, eg (2, 400)\n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        for sub in v2_subs:\n",
    "\n",
    "            sname = sub.split(\"_\")[0]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sname+'/segmented_files/'+sub)\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) \n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        #build the ISC array\n",
    "        single_clip_mat_arr = np.array(single_clip_matrix_list)\n",
    "        \n",
    "        for p in range(400):\n",
    "            sub_clip_corr = np.corrcoef(single_clip_mat_arr[:,:,p]) #(28,28)\n",
    "            ratings_flat, isc_flat = rating_matrix.flatten(), sub_clip_corr.flatten()\n",
    "            const = sm.add_constant(ratings_flat)\n",
    "            model = sm.OLS(isc_flat, const)\n",
    "            results = model.fit()\n",
    "            clip_to_behavior_correlation[cx,p] = results.params[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='teal'>Mantel Test (Permutations)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movie_list[0:1]:\n",
    "\n",
    "    movie_cliplist = [x for x in complete_cliplist if movie in x]\n",
    "\n",
    "    clip_to_version_permutations = np.zeros([12,400,10000])\n",
    "\n",
    "    for cx, clip in enumerate(working_list[1:2]):\n",
    "\n",
    "        clip_number = int(clip.split(\"-\")[1])\n",
    "        trait_arr = np.empty([6,3])\n",
    "\n",
    "        for ix, trait in enumerate(traitlist):\n",
    "            trait_arr[ix,:] = calculate_distances(cloud_ratings, movie, trait, clip_number)\n",
    "        \n",
    "        #get v1, v2, and v1v2 values:\n",
    "        trait_avg = trait_arr.mean(axis=0)\n",
    "\n",
    "        #build out clip-specific rating matrix based on participant version matrix\n",
    "        rating_matrix = np.empty([28,28])\n",
    "\n",
    "        for r in range(28):\n",
    "            for c in range(28):\n",
    "                if version_matrix[r,c] == 'v1v1':\n",
    "                    rating_matrix[r,c] = trait_avg[0]\n",
    "                elif version_matrix[r,c] == 'v2v2':\n",
    "                    rating_matrix[r,c] = trait_avg[1]\n",
    "                else:\n",
    "                    rating_matrix[r,c] = trait_avg[2]\n",
    "\n",
    "        #now resume building the clip's subject-wide ISC matrix\n",
    "        filtered_clips = [x for x in movie_cliplist if clip+\"_\" in x]\n",
    "        \n",
    "        #this ensures that the subject order matches the distance_matrices orders\n",
    "        v1_subs = natsorted([x for x in filtered_clips if 'version-1' in x])\n",
    "        v2_subs = natsorted([x for x in filtered_clips if 'version-2' in x])\n",
    "\n",
    "        single_clip_matrix_list = []\n",
    "\n",
    "        for sub in v1_subs:\n",
    "\n",
    "            sname = sub.split(\"_\")[0]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sname+'/segmented_files/'+sub)\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) #producess a timepoint x parcel csv, eg (2, 400)\n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        for sub in v2_subs:\n",
    "\n",
    "            sname = sub.split(\"_\")[0]\n",
    "\n",
    "            clip_segment_nii = nb.load(segmented_clip_path+sname+'/segmented_files/'+sub)\n",
    "\n",
    "            time_by_parcel = masker.fit_transform(clip_segment_nii) \n",
    "            single_clip_matrix_list.append(time_by_parcel)\n",
    "        \n",
    "        #build the ISC array\n",
    "        single_clip_mat_arr = np.array(single_clip_matrix_list)\n",
    "        \n",
    "        for p in range(400):\n",
    "            np.random.seed(0)\n",
    "            sub_clip_corr = np.corrcoef(single_clip_mat_arr[:,:,p]) #(28,28)\n",
    "            \n",
    "            for perm in range(2):\n",
    "                random_array = np.random.permutation(28)\n",
    "                shuffled_matrix = sub_clip_corr[random_array][:, random_array]\n",
    "\n",
    "                ratings_flat, isc_flat = rating_matrix.flatten(), shuffled_matrix.flatten()\n",
    "                const = sm.add_constant(ratings_flat)\n",
    "                model = sm.OLS(isc_flat, const)\n",
    "                results = model.fit()\n",
    "\n",
    "                clip_to_version_permutations[cx,p, perm] = results.params[1] \n",
    "    \n",
    "    np.save(movie+'_isRSA_cleaned_permutation_matrix_'+monologue_type, clip_to_version_permutations.mean(axis=0)) #average across clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='teal'>Visualize the results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, datasets, image, surface\n",
    "import nibabel as nb\n",
    "from nilearn.plotting import plot_img_on_surf\n",
    "from nilearn.image import new_img_like\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "\n",
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "    data_dir=None, base_url=None, resume=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgoldenrod'>Internal Monologues IS-RSA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the two different movie permutations and then average across them\n",
    "phys_im, stut_im = pd.read_csv('physical_clips_by_parcel_IM.csv', index_col=0), pd.read_csv('stutterer_clips_by_parcel_IM.csv', index_col=0)\n",
    "phys_im_avg, stut_im_avg = phys_im.mean(axis=0).reset_index(drop=True), stut_im.mean(axis=0).reset_index(drop=True)\n",
    "im_avg = np.array(list((phys_im_avg + stut_im_avg) / 2)) # (400)\n",
    "\n",
    "phys_perm_im,  stut_perm_im = np.load('/Volumes/Scraplab/lindseytepfer/inarr/physical_isRSA_permutation_matrix_IM.npy'), np.load('/Volumes/Scraplab/lindseytepfer/inarr/stutterer_isRSA_permutation_matrix_IM.npy')\n",
    "perm_avg_im = np.mean([phys_perm_im, stut_perm_im], axis=0) # (400, 10000)\n",
    "\n",
    "permuted_vals = np.abs(perm_avg_im) # (400, 10000)\n",
    "null_dist = permuted_vals.max(axis=0) #shape = (10000)\n",
    "\n",
    "results_pvals = np.empty((400))\n",
    "\n",
    "for parcel in range(im_avg.shape[0]): #400, for each parcel\n",
    "    results_pvals[parcel] = np.mean(null_dist[:] >= abs(im_avg[parcel]))\n",
    "\n",
    "significant = np.where(results_pvals < 0.01, 1, 0) #(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create corr image\n",
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "\n",
    "#need to insert the 0 for proper indexing. \n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")\n",
    "\n",
    "atlas = nb.load(schaefer_atlas.maps) # .maps provides the path to the map\n",
    "atlas_data = atlas.get_fdata()\n",
    "\n",
    "mapped_data = np.zeros_like(atlas_data)\n",
    "mapped_data[atlas_data == 0] = np.nan # mark\n",
    "unique_regions = np.unique(atlas_data)[1:]\n",
    "\n",
    "for i, region in enumerate(unique_regions):\n",
    "    mapped_data[atlas_data == region] = im_avg[i]\n",
    "\n",
    "corr_im_img = nb.Nifti1Image(mapped_data, atlas.affine)\n",
    "#nb.save(corr_im_img, 'corr_im_map.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corrected p-value mask:\n",
    "n_rois = 399\n",
    "\n",
    "roi_data = image.get_data(atlas)  # (x,y,z) array with ROI labels\n",
    "significant_mask = np.zeros_like(roi_data, dtype=np.float32)\n",
    "\n",
    "for roi_label in range(1, n_rois+1):\n",
    "    if significant[roi_label-1] == 1:  # ROI labels start at 1\n",
    "        significant_mask[roi_data == roi_label] = 1  # Tag significant voxels\n",
    "\n",
    "mask_img = new_img_like(atlas, significant_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Internal Monologue results\n",
    "\n",
    "plotting.plot_img_on_surf(corr_im_img,\n",
    "    \"fsaverage\", inflate=True,\n",
    "    views=['lateral', 'medial'],  # Hemispheric views to display\n",
    "    hemispheres=['left', 'right'],  # Both hemispheres\n",
    "    #threshold=0.05,  # Highlight significant p-values\n",
    "    cmap='seismic',  # Colormap (e.g., 'viridis', 'coolwarm')\n",
    "    colorbar=True,  # Show colorbar\n",
    "    mask_img=mask_img,\n",
    "    vmin=-1, vmax=1, #removing these options to let it be automatic\n",
    ")\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('isc_corrected.png', dpi=300, facecolor='w', bbox_inches='tight')\n",
    "# plt.close()\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgoldenrod'>Non-internal Monologues IS-RSA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the two different movie permutations and then average across them\n",
    "phys_nim, stut_nim = pd.read_csv('physical_clips_by_parcel_NIM.csv',index_col=0), pd.read_csv('stutterer_clips_by_parcel_NIM.csv',index_col=0)\n",
    "phys_nim_avg, stut_nim_avg = phys_nim.mean(axis=0).reset_index(drop=True), stut_nim.mean(axis=0).reset_index(drop=True)\n",
    "\n",
    "nim_avg = np.array(list((phys_nim_avg + stut_nim_avg) / 2))\n",
    "phys_perm_nim,  stut_perm_nim = np.load('/Volumes/Scraplab/lindseytepfer/inarr/physical_isRSA_permutation_matrix_NIM.npy'), np.load('/Volumes/Scraplab/lindseytepfer/inarr/stutterer_isRSA_permutation_matrix_NIM.npy')\n",
    "perm_avg_nim = np.mean([phys_perm_nim, stut_perm_nim], axis=0) # (400, 10000)\n",
    "\n",
    "permuted_vals = np.abs(perm_avg_nim) # (400, 10000)\n",
    "null_dist = permuted_vals.max(axis=0) #shape = (10000)\n",
    "\n",
    "results_pvals = np.empty((400))\n",
    "\n",
    "for parcel in range(nim_avg.shape[0]): #400, for each parcel\n",
    "    results_pvals[parcel] = np.mean(null_dist[:] >= abs(nim_avg[parcel]))\n",
    "\n",
    "significant = np.where(results_pvals < 0.01, 1, 0) #(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create corr image\n",
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "\n",
    "#need to insert the 0 for proper indexing. \n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")\n",
    "\n",
    "atlas = nb.load(schaefer_atlas.maps) # .maps provides the path to the map\n",
    "atlas_data = atlas.get_fdata()\n",
    "\n",
    "mapped_data = np.zeros_like(atlas_data)\n",
    "mapped_data[atlas_data == 0] = np.nan # mark\n",
    "unique_regions = np.unique(atlas_data)[1:]\n",
    "\n",
    "for i, region in enumerate(unique_regions):\n",
    "    mapped_data[atlas_data == region] = nim_avg[i]\n",
    "\n",
    "corr_nim_img = nb.Nifti1Image(mapped_data, atlas.affine)\n",
    "#nb.save(corr_nim_img, 'corr_nim_map.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corrected p-value mask:\n",
    "n_rois = 399\n",
    "\n",
    "roi_data = image.get_data(atlas)  # (x,y,z) array with ROI labels\n",
    "significant_mask = np.zeros_like(roi_data, dtype=np.float32)\n",
    "\n",
    "for roi_label in range(1, n_rois+1):\n",
    "    if significant[roi_label-1] == 1:  # ROI labels start at 1\n",
    "        significant_mask[roi_data == roi_label] = 1  # Tag significant voxels\n",
    "\n",
    "mask_img = new_img_like(atlas, significant_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Non-internal Monologue results\n",
    "\n",
    "plotting.plot_img_on_surf(corr_nim_img,\n",
    "    \"fsaverage\", inflate=True,\n",
    "    views=['lateral', 'medial'],  # Hemispheric views to display\n",
    "    hemispheres=['left', 'right'],  # Both hemispheres\n",
    "    #threshold=0.05,  # Highlight significant p-values\n",
    "    cmap='seismic',  # Colormap (e.g., 'viridis', 'coolwarm')\n",
    "    colorbar=True,  # Show colorbar\n",
    "    mask_img=mask_img,\n",
    "    vmin=-1, vmax=1, #removing these options to let it be automatic\n",
    ")\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('isc_corrected.png', dpi=300, facecolor='w', bbox_inches='tight')\n",
    "# plt.close()\n",
    "\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
